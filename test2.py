import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
import os
import tempfile
import threading
import json
import librosa
import soundfile as sf
from aip import AipSpeech
import speech_recognition as sr
import uuid  # ç”¨äºç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å

# è®¾ç½®ç¼–ç 
os.environ["PYTHONIOENCODING"] = "utf-8"
os.environ["LANG"] = "en_US.UTF-8"

# ç™¾åº¦è¯­éŸ³è¯†åˆ«é…ç½®ï¼ˆæ›¿æ¢ä¸ºä½ çš„APIä¿¡æ¯ï¼‰
BAIDU_APP_ID = "119055690"
BAIDU_API_KEY = "Ui908c5FJoScXlNyK7zuXR1Z"
BAIDU_SECRET_KEY = "uqckQD7hKf90VgfjFnaclil4MZ8piEnE"
baidu_client = AipSpeech(BAIDU_APP_ID, BAIDU_API_KEY, BAIDU_SECRET_KEY)

# é€‰æ‹©APIæä¾›å•†
API_PROVIDERS = {
    "twapi": "https://twapi.openai-hk.com/v1",
    "nengyongai": "https://ai.nengyongai.cn",

}


def get_ai_response(user_prompt):
    try:
        # åˆ›å»ºLLMå®ä¾‹
        model = ChatOpenAI(
            model='gpt-4o-mini',
            api_key=st.session_state.get('API_KEY', ''),
            base_url=st.session_state.get('API_BASE_URL', API_PROVIDERS["nengyongai"])
        )

        # åˆ›å»ºå¯¹è¯é“¾
        chain = ConversationChain(llm=model, memory=st.session_state['memory'])

        # è·å–AIå“åº”
        response = chain.invoke({'input': user_prompt})['response']
        return response

    except Exception as e:
        # æ•è·å¹¶å¤„ç†APIè°ƒç”¨å¼‚å¸¸
        error_msg = f"è·å–AIå“åº”å¤±è´¥: {str(e)}"
        st.error(error_msg)
        return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥æˆ–ç¨åå†è¯•ã€‚"


def convert_mp3_to_wav(mp3_path, wav_path='temp.wav'):
    """ä½¿ç”¨çº¯Pythonæ–¹æ¡ˆå°†MP3è½¬æ¢ä¸ºWAVæ ¼å¼"""
    try:
        y, sr = librosa.load(mp3_path, sr=16000)  # åŠ è½½å¹¶é‡é‡‡æ ·åˆ°16kHz
        sf.write(wav_path, y, sr, subtype='PCM_16')  # ä¿å­˜ä¸º16ä½PCM WAV
        return wav_path
    except Exception as e:
        print(f"Librosaè½¬æ¢å¤±è´¥: {str(e)}")
        return None


def speech_to_text(audio_path, is_mp3=False):
    wav_path = None
    try:
        if is_mp3:
            # ä»…ä½¿ç”¨librosaæ–¹æ¡ˆï¼ˆæ— éœ€ffmpegï¼‰
            wav_path = convert_mp3_to_wav(audio_path)
            if not wav_path:
                return "MP3è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥librosaåº“"
            audio_file = wav_path
        else:
            audio_file = audio_path

        result = baidu_client.asr(
            get_file_content(audio_file),
            'wav', 16000,
            {'dev_pid': 1537}
        )

        if result.get('err_no') == 0:
            return ''.join(result.get('result', []))
        else:
            return f"è¯†åˆ«å¤±è´¥: {result.get('err_msg', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"å‘ç”Ÿå¼‚å¸¸: {str(e)}"
    finally:
        if wav_path and os.path.exists(wav_path):
            os.remove(wav_path)


def get_file_content(filePath):
    with open(filePath, 'rb') as fp:
        return fp.read()


def handle_uploaded_file(file_input):
    if isinstance(file_input, str):  # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
        file_path = file_input
        file_name = os.path.basename(file_path)
    else:  # å¦‚æœæ˜¯ UploadedFile å¯¹è±¡
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„å†…å®¹
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file_input.name)[1]) as f:
            f.write(file_input.getbuffer())
            file_path = f.name
            file_name = file_input.name

    is_mp3 = file_name.lower().endswith('.mp3')
    text = speech_to_text(file_path, is_mp3)

    # å¦‚æœæ˜¯ä¸´æ—¶æ–‡ä»¶ï¼Œå¤„ç†å®Œååˆ é™¤
    if not isinstance(file_input, str):
        os.remove(file_path)

    return text


def record_audio():
    """å½•åˆ¶éŸ³é¢‘å¹¶ä¿å­˜ä¸ºWAVæ–‡ä»¶"""
    r = sr.Recognizer()

    with sr.Microphone() as source:
        st.write(f"å¼€å§‹å½•éŸ³...")
        audio = r.listen(source)  # å½•åˆ¶éŸ³é¢‘

    # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
    output_file = f"{uuid.uuid4()}.wav"

    # ä¿å­˜ä¸ºWAVæ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
        f.write(audio.get_wav_data())
        temp_wav = f.name

    # ç¡®ä¿éŸ³é¢‘æ ¼å¼ç¬¦åˆç™¾åº¦APIè¦æ±‚ï¼ˆ16ä½å•å£°é“ï¼Œ16000Hzï¼‰
    try:
        # ä½¿ç”¨pydubè½¬æ¢æ ¼å¼ï¼ˆéœ€æå‰å®‰è£…ï¼‰
        from pydub import AudioSegment

        sound = AudioSegment.from_wav(temp_wav)
        # è½¬æ¢ä¸º16ä½ã€16000Hzã€å•å£°é“
        sound = sound.set_sample_width(2)  # 16ä½
        sound = sound.set_frame_rate(16000)
        sound = sound.set_channels(1)  # å•å£°é“
        sound.export(output_file, format="wav")
        st.write(f"éŸ³é¢‘å·²ä¿å­˜è‡³: {os.path.abspath(output_file)}")
    except ImportError:
        # è‹¥æœªå®‰è£…pydubï¼Œç›´æ¥å¤åˆ¶ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯èƒ½æ ¼å¼ä¸æ ‡å‡†ï¼‰
        import shutil
        shutil.copy(temp_wav, output_file)
        st.write(f"å·²ä¿å­˜åŸå§‹WAVæ–‡ä»¶è‡³: {os.path.abspath(output_file)}")
    finally:
        os.remove(temp_wav)

    # æ›´æ–° last_uploaded_file
    st.session_state['last_uploaded_file'] = output_file
    return output_file


# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="æˆ‘çš„ChatGPT",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title('æˆ‘çš„ChatGPT')

with st.sidebar:
    st.header("é…ç½®")

    # APIæä¾›å•†é€‰æ‹©
    api_provider = st.selectbox(
        "é€‰æ‹©APIæä¾›å•†",
        list(API_PROVIDERS.keys()),
        index=0,
        key="api_provider_select"
    )

    st.session_state['API_BASE_URL'] = API_PROVIDERS[api_provider]

    # APIå¯†é’¥è¾“å…¥
    api_key_input = st.text_input(
        'è¯·è¾“å…¥ä½ çš„API Keyï¼š',
        type='password',
        key="api_key_input"
    )

    # ä¿å­˜APIå¯†é’¥åˆ°session_state
    if api_key_input:
        st.session_state['API_KEY'] = api_key_input

    st.markdown("---")
    st.info("""
    **æç¤ºï¼š**
    - è¯·ç¡®ä¿è¾“å…¥çš„APIå¯†é’¥æœ‰æ•ˆ
    - å®˜æ–¹OpenAI APIéœ€è¦æœ‰æ•ˆçš„OpenAIè´¦æˆ·
    - ç¬¬ä¸‰æ–¹æœåŠ¡å¯èƒ½æœ‰ä¸åŒçš„ä½¿ç”¨é™åˆ¶
    """)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'messages' not in st.session_state:
    st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ä¸»äººï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæˆ‘å«å°ç¾'}]
    st.session_state['memory'] = ConversationBufferMemory(return_message=True)

if 'voice_text' not in st.session_state:
    st.session_state['voice_text'] = ""

if 'user_input' not in st.session_state:
    st.session_state['user_input'] = ""

if 'submit_voice' not in st.session_state:
    st.session_state['submit_voice'] = False


# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state['messages']:
    role, content = message['role'], message['content']
    st.chat_message(role).write(content)

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=['mp3', 'wav'])

# æ¸…é™¤æ—§çš„éŸ³é¢‘æ–‡ä»¶å¼•ç”¨
def clear_old_audio_file():
    if 'last_uploaded_file' in st.session_state:
        if os.path.exists(st.session_state['last_uploaded_file']):
            os.remove(st.session_state['last_uploaded_file'])
        st.session_state.pop('last_uploaded_file', None)
# å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
if uploaded_file is not None:
    # é‡ç½®ç”¨æˆ·è¾“å…¥çŠ¶æ€
    st.session_state['voice_text'] = ""
    st.session_state['user_input'] = ""
    st.session_state['submit_voice'] = False
    with st.spinner("æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶..."):
        text = handle_uploaded_file(uploaded_file)
        st.session_state['voice_text'] = text
        st.session_state['user_input'] = text
        st.session_state['submit_voice'] = True
        st.session_state['last_uploaded_file'] = uploaded_file.name  # è®°å½•å½“å‰æ–‡ä»¶å
        st.session_state.pop('uploaded_file', None)  # æ¸…é™¤sessionä¸­çš„æ–‡ä»¶å¼•ç”¨
        uploaded_file = None  # æ¸…é™¤å½“å‰æ–‡ä»¶å¼•ç”¨

# å½•åˆ¶éŸ³é¢‘æŒ‰é’®
if st.button("å½•åˆ¶éŸ³é¢‘"):
    clear_old_audio_file()  # æ¸…é™¤æ—§çš„éŸ³é¢‘æ–‡ä»¶å¼•ç”¨

    # é‡ç½®ç”¨æˆ·è¾“å…¥çŠ¶æ€
    st.session_state['voice_text'] = ""
    st.session_state['user_input'] = ""
    st.session_state['submit_voice'] = False
    st.session_state.pop('uploaded_file', None)

    with st.spinner("æ­£åœ¨å½•åˆ¶éŸ³é¢‘..."):
        output_file = record_audio()
        text = handle_uploaded_file(output_file)
        st.session_state['voice_text'] = text
        st.session_state['user_input'] = text
        st.session_state['submit_voice'] = True
        st.session_state['last_uploaded_file'] = output_file  # è®°å½•å½“å‰æ–‡ä»¶å
        os.remove(output_file)  # å¤„ç†å®Œååˆ é™¤å½•éŸ³æ–‡ä»¶
# è¾“å…¥åŒºåŸŸ
user_input = st.chat_input("è¾“å…¥æ–‡å­—æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
if user_input:
    # æ¸…é™¤éŸ³é¢‘ç›¸å…³çŠ¶æ€
    st.session_state['voice_text'] = ""
    st.session_state['user_input'] = ""
    st.session_state['submit_voice'] = False
    st.session_state.pop('uploaded_file', None)

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input or st.session_state.get('submit_voice', False):
    # è·å–APIå¯†é’¥
    api_key = st.session_state.get('API_KEY', '')

    # åŒºåˆ†å¤„ç†éŸ³é¢‘è¾“å…¥å’Œæ–‡æœ¬è¾“å…¥
    if st.session_state.get('submit_voice', False):
        user_input = st.session_state['user_input']
        st.session_state['submit_voice'] = False
        input_type = "éŸ³é¢‘"
    else:
        input_type = "æ–‡æœ¬"

    # æ£€æŸ¥APIå¯†é’¥
    if not api_key:
        st.warning('è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„API Keyï¼')
        st.stop()

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message('human').write(user_input)
    st.session_state['messages'].append({'role': 'human', 'content': user_input})

    # è®°å½•è¾“å…¥ç±»å‹ï¼ˆå¯é€‰ï¼‰
    st.session_state['last_input_type'] = input_type

    # è·å–AIå“åº”
    with st.spinner('AIæ­£åœ¨æ€è€ƒï¼Œè¯·ç­‰å¾…â€¦â€¦'):
        resp_from_ai = get_ai_response(user_input)
        st.chat_message('ai').write(resp_from_ai)
        st.session_state['messages'].append({'role': 'ai', 'content': resp_from_ai})

    # å¤„ç†å®Œåé‡ç½®éŸ³é¢‘è¾“å…¥çŠ¶æ€
    if input_type == "éŸ³é¢‘":
        st.session_state['user_input'] = ""
        st.session_state['voice_text'] = ""